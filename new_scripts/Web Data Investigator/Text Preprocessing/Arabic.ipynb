{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip  install pyarabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install aiogoogletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install snowballstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "import emoji\n",
    "from aiogoogletrans import Translator\n",
    "import asyncio\n",
    "import string\n",
    "import re\n",
    "import pyarabic.araby as araby\n",
    "from pyarabic.araby import strip_tatweel\n",
    "from pyarabic import araby\n",
    "from snowballstemmer import stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "# Arabic stopwords\n",
    "arabic_stopwords = stopwords.words('arabic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emails(text):\n",
    "\temails = re.findall(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+\\b)', text)\n",
    "\treturn emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_hashtag_to_words(tag):\n",
    "    tag = tag.replace('#', '')\n",
    "    tags = tag.split('_')\n",
    "    if len(tags) > 1:\n",
    "        return tags\n",
    "    else:\n",
    "        return [tag]\n",
    "\n",
    "def extract_hashtag(text):\n",
    "    hash_list = ([re.sub(r\"(\\W+)$\", \"\", i) for i in text.split() if i.startswith(\"#\")])\n",
    "    word_list = []\n",
    "    for word in hash_list:\n",
    "        word_list.extend(split_hashtag_to_words(word))\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['جيد', 'استخراج', 'الوسم']\n"
     ]
    }
   ],
   "source": [
    "text = \"هذا هو مثال #جيد لاختبار الوظيفة #استخراج_الوسم\"\n",
    "result = extract_hashtag(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['التحدث', 'التعبير', '']\n"
     ]
    }
   ],
   "source": [
    "text = \"هل جربت #التحدث بالإيموجي؟ يضيف للمحادثات #التعبير_ عن المشاعر بشكل ممتع! 😊📱\"\n",
    "result = extract_hashtag(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['مستخدم1', 'مستخدم2']\n"
     ]
    }
   ],
   "source": [
    "def extract_mentions_arabic(text):\n",
    "    mentions = re.findall(r'@(\\w+)', text)\n",
    "    return mentions\n",
    "\n",
    "\n",
    "text_arabic = \"مرحبا @مستخدم1 و @مستخدم2، كيف حالكم؟\"\n",
    "mentions_arabic = extract_mentions_arabic(text_arabic)\n",
    "print(mentions_arabic)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- get urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https', 'example.com', ''), ('https', 'example.org', '')]\n"
     ]
    }
   ],
   "source": [
    "def extract_urls(text):\n",
    "\turls = re.findall(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?',text)\n",
    "\treturn urls\n",
    "\n",
    "\n",
    "text = \"قم بزيارة هذا الموقع: https://example.com، وأيضًا https://example.org\"\n",
    "urls = extract_urls(text)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- treat hashtags : remove the whole hashtag or just the character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hashtag(text):\n",
    "    words = text.split()\n",
    "    text = list()\n",
    "    for word in words:\n",
    "        if is_hashtag(word):\n",
    "            text.extend(extract_hashtag(word))\n",
    "        else:\n",
    "            text.append(word)\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "def is_hashtag(word):\n",
    "    if word.startswith(\"#\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def remove_hashtag_char(text):\n",
    "    mention_pattern = r'#+'\n",
    "    cleaned_text = re.sub(mention_pattern, '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مرحبا كيف حالك؟ منشن dfhg لـ @مستخدم2 في هذا التغريدة.\n"
     ]
    }
   ],
   "source": [
    "text = \"مرحبا  كيف حالك؟ منشن #dfhg#  لـ @مستخدم2 في هذا التغريدة.\"\n",
    "cleaned_text = clean_hashtag(text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- remove mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مرحبا مستخدم1، كيف حالك؟ منشن لـ مستخدم2 في هذا التغريدة.\n"
     ]
    }
   ],
   "source": [
    "def remove_mentions(text):\n",
    "    mention_pattern = r'@+'\n",
    "    cleaned_text = re.sub(mention_pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "text = \"مرحبا @مستخدم1، كيف حالك؟ منشن لـ @مستخدم2 في هذا التغريدة.\"\n",
    "cleaned_text = remove_mentions(text)\n",
    "print(cleaned_text)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- replace emojis \"only arabic case is treated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emojis.csv','r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    emojis_ar = {}\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split(';')\n",
    "        emojis_ar.update({line[0].strip():line[1].strip()})\n",
    "\n",
    "\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  \n",
    "                                   u\"\\U0001F300-\\U0001F5FF\" \n",
    "                                   u\"\\U0001F680-\\U0001F6FF\" \n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def emoji_native_translation(text):\n",
    "    text = text.lower()\n",
    "    loves = [\"<3\", \"♥\",'❤']\n",
    "    smilefaces = []\n",
    "    sadfaces = []\n",
    "    neutralfaces = []\n",
    "\n",
    "    eyes = [\"8\",\":\",\"=\",\";\"]\n",
    "    nose = [\"'\",\"`\",\"-\",r\"\\\\\"]\n",
    "    for e in eyes:\n",
    "        for n in nose:\n",
    "            for s in [\"\\)\", \"d\", \"]\", \"}\",\"p\"]:\n",
    "                smilefaces.append(e+n+s)\n",
    "                smilefaces.append(e+s)\n",
    "            for s in [\"\\(\", \"\\[\", \"{\"]:\n",
    "                sadfaces.append(e+n+s)\n",
    "                sadfaces.append(e+s)\n",
    "            for s in [\"\\|\", \"\\/\", r\"\\\\\"]:\n",
    "                neutralfaces.append(e+n+s)\n",
    "                neutralfaces.append(e+s)\n",
    "            #reversed\n",
    "            for s in [\"\\(\", \"\\[\", \"{\"]:\n",
    "                smilefaces.append(s+n+e)\n",
    "                smilefaces.append(s+e)\n",
    "            for s in [\"\\)\", \"\\]\", \"}\"]:\n",
    "                sadfaces.append(s+n+e)\n",
    "                sadfaces.append(s+e)\n",
    "            for s in [\"\\|\", \"\\/\", r\"\\\\\"]:\n",
    "                neutralfaces.append(s+n+e)\n",
    "                neutralfaces.append(s+e)\n",
    "\n",
    "    smilefaces = list(set(smilefaces))\n",
    "    sadfaces = list(set(sadfaces))\n",
    "    neutralfaces = list(set(neutralfaces))\n",
    "    t = []\n",
    "    for w in text.split():\n",
    "        if w in loves:\n",
    "            t.append(\"حب\")\n",
    "        elif w in smilefaces:\n",
    "            t.append(\"مضحك\")\n",
    "        elif w in neutralfaces:\n",
    "            t.append(\"عادي\")\n",
    "        elif w in sadfaces:\n",
    "            t.append(\"محزن\")\n",
    "        else:\n",
    "            t.append(w)\n",
    "    newText = \" \".join(t)\n",
    "    return newText\n",
    "\n",
    "   \n",
    "def is_emoji(word):\n",
    "    if word in emojis_ar:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "def translate_emojis(words):\n",
    "    word_list = list()\n",
    "    words_to_translate = list()\n",
    "    for word in words :\n",
    "        t = emojis_ar.get(word.get('emoji'),None)\n",
    "        if t is None:\n",
    "            word.update({'translation':'عادي','translated':True})\n",
    "            #words_to_translate.append('normal')\n",
    "        else:\n",
    "            word.update({'translated':False,'translation':t})\n",
    "            words_to_translate.append(t.replace(':','').replace('_',' '))\n",
    "        word_list.append(word)\n",
    "    return word_list\n",
    "\n",
    "def emoji_unicode_translation(text):\n",
    "    text = add_space(text)\n",
    "    words = text.split()\n",
    "    text_list = list()\n",
    "    emojis_list = list()\n",
    "    c = 0\n",
    "    for word in words:\n",
    "        if is_emoji(word):\n",
    "            emojis_list.append({'emoji':word,'emplacement':c})\n",
    "        else:\n",
    "            text_list.append(word)\n",
    "        c+=1\n",
    "    emojis_translated = translate_emojis(emojis_list)\n",
    "    for em in emojis_translated:\n",
    "        text_list.insert(em.get('emplacement'),em.get('translation'))\n",
    "    text = \" \".join(text_list)\n",
    "    return text\n",
    "    \n",
    "def clean_emoji(text):\n",
    "    text = emoji_native_translation(text)\n",
    "    text = emoji_unicode_translation(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أحبك قلب احمر خدود\n",
      "أنا حزين جدًا يبكي\n",
      "أنا في حالة مزاجية جيدة ابتسامة\n"
     ]
    }
   ],
   "source": [
    "text_with_emojis = \"أحبك ❤️😊\"\n",
    "cleaned_text = clean_emoji(text_with_emojis)\n",
    "print(cleaned_text)\n",
    "\n",
    "\n",
    "text_with_emojis = \"أنا حزين جدًا 😢\"\n",
    "cleaned_text = clean_emoji(text_with_emojis)\n",
    "print(cleaned_text)\n",
    "\n",
    "\n",
    "text_with_emojis = \"أنا في حالة مزاجية جيدة 😄\"\n",
    "cleaned_text = clean_emoji(text_with_emojis)\n",
    "print(cleaned_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emails(text):\n",
    "\treturn re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+\\b)',\"\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?',\"\",text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic text with URLs removed: تحقق من هذا الرابط: ، إنه رائع!\n"
     ]
    }
   ],
   "source": [
    "text = \"تحقق من هذا الرابط: https://example.com، إنه رائع!\"\n",
    "cleaned_text = remove_urls(text)\n",
    "print(\"Arabic text with URLs removed:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- remove punctuations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_punctuation = string.punctuation\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    return re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text with punctuations removed: تحقق من هذا الرابط  https   example com  إنه رائع \n"
     ]
    }
   ],
   "source": [
    "text = \"تحقق من هذا الرابط: https://example.com، إنه رائع!\"\n",
    "cleaned_text = remove_punctuations(text)\n",
    "\n",
    "print(\"text with punctuations removed:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove non used arabic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_arabic(text):\n",
    "    arabic_pattern = re.compile(r'[^\\u0600-\\u06FF\\u0750-\\u077F\\d\\s]+')\n",
    "    cleaned_text = arabic_pattern.sub('', text)\n",
    "    \n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove repeated characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_characters(text):\n",
    "    repeated_pattern = re.compile(r'(\\S)(\\1)+', re.UNICODE)\n",
    "    cleaned_text = repeated_pattern.sub(r'\\1', text)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with repeated characters removed: هذا هو نص مكر\n"
     ]
    }
   ],
   "source": [
    "text = \"هذاااا هوووو نص مككككككرررررررررررررررررررررررررر\"\n",
    "cleaned_text = remove_repeated_characters(text)\n",
    "print(\"Text with repeated characters removed:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11- for arabic remove tashkeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= araby.strip_tashkeel(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip tatweel from a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "العربية\n"
     ]
    }
   ],
   "source": [
    "text = u\"العـــــربية\"\n",
    "print(strip_tatweel(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalizeArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeArabic(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(noise, '', text)\n",
    "    text = re.sub(r'(.)\\1+', r\"\\1\\1\", text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_arabic_stopwords_tokenize(text):    \n",
    "    tokens = araby.tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stopwords.words()]\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with Arabic stopwords removed: ['نص', 'تجريبي', 'يحتوي', 'الكلمات', 'العربية', 'العادية']\n"
     ]
    }
   ],
   "source": [
    "text = \"هذا هو نص تجريبي يحتوي على بعض الكلمات العربية العادية\"\n",
    "cleaned_text = remove_arabic_stopwords_tokenize(text)\n",
    "print(\"Text with Arabic stopwords removed:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ياكل\n"
     ]
    }
   ],
   "source": [
    "def stem_arabic_word(word):\n",
    "    arabic_stemmer = stemmer(\"arabic\")\n",
    "    stemmed_word = arabic_stemmer.stemWord(word)\n",
    "    return stemmed_word\n",
    "\n",
    "word = \"يأكلون\"\n",
    "stemmed_word = stem_arabic_word(word)\n",
    "print(stemmed_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove multipe spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multiple_spaces(text):\n",
    "\treturn ' '.join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'العربية لغة جميلة.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = u\"العربية لغة       جميلة.\"\n",
    "remove_multiple_spaces(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the proposed algorithm to treat the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user@gmail.com']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"user@gmail.com\"\n",
    "get_emails(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['التحدث', 'التعبير']\n"
     ]
    }
   ],
   "source": [
    "text = \"هل جربت #التحدث بالإيموجي؟ يضيف للمحادثات #التعبير عن المشاعر بشكل ممتع! 😊📱\"\n",
    "result = extract_hashtag(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['مستخدم1', 'مستخدم2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"مرحبا @مستخدم1 و @مستخدم2، كيف حالكم؟\"\n",
    "mentions = extract_mentions_arabic(text)\n",
    "print(mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https', 'example.com', ''), ('https', 'example.org', '')]\n"
     ]
    }
   ],
   "source": [
    "text_with_urls = \"قم بزيارة هذا الموقع: https://example.com، وأيضًا https://example.org\"\n",
    "urls = extract_urls(text_with_urls)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = clean_hashtag(text)\n",
    "    text = clean_emoji(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_non_arabic(text)\n",
    "    text = remove_repeated_characters(text)\n",
    "    text = remove_multiple_spaces(text)\n",
    "    tokens = remove_arabic_stopwords_tokenize(text)\n",
    "    for i, word in enumerate(tokens):\n",
    "        diacritic_removed_word = araby.strip_tashkeel(word)\n",
    "        final_word = strip_tatweel(diacritic_removed_word)\n",
    "        normalized_word = normalizeArabic(final_word)\n",
    "        stemmed_word = stem_arabic_word(normalized_word)\n",
    "        tokens[i] = stemmed_word\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['قم', 'زيار', '12', 'موقع', 'ايض']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_text_with_urls = \"قم       بزيارة 12 هذا الموقع: https://example.com، و أيضًا https://example.org\"\n",
    "clean_text(arabic_text_with_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
